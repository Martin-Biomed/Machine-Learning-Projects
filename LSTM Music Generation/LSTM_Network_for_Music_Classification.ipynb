{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_Network_for_Music_Classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMVQLfgFdC1pwZsxi4VtcuS"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"UW_fljlImEi8"},"source":["# This project is almost identical to the tutorial by Valerio Velardo: \n","\n","import json\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import tensorflow.keras as keras\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eg5R4Fu2mG37","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615203879860,"user_tz":-630,"elapsed":79719,"user":{"displayName":"martin gallo","photoUrl":"","userId":"09197733274002682158"}},"outputId":"36733953-b859-49ed-eb47-b66fb19b7a59"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive') "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1dPyhz5UmJUS"},"source":["DATA_PATH = \"/content/gdrive/MyDrive/ML_Datasets/data_10.json\" # This refers to the JSON file created by using the \"GTZAN_data_to_JSON\" script"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eKydDBbKmWmc"},"source":["def load_data(data_path):\n","    #Loads training dataset from json file.\n","        # data_path is a string which lists the path to json file containing data\n","        # X = Inputs\n","        # y = Targets\n","\n","    with open(data_path, \"r\") as fp:\n","        data = json.load(fp)\n","\n","    X = np.array(data[\"mfcc\"])\n","    y = np.array(data[\"labels\"])\n","\n","    print('Shape of X: ' + X.shape)\n","    print('Shape of y: ' + y.shape)\n","\n","    return X, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9TS3d1Lemrkb"},"source":["def plot_history(history):\n","    \n","    # Plots accuracy/loss for training/validation set as a function of the epochs\n","\n","    fig, axs = plt.subplots(2)\n","\n","    # create accuracy sublpot\n","    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n","    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n","    axs[0].set_ylabel(\"Accuracy\")\n","    axs[0].legend(loc=\"lower right\")\n","    axs[0].set_title(\"Accuracy eval\")\n","\n","    # create error sublpot\n","    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n","    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n","    axs[1].set_ylabel(\"Error\")\n","    axs[1].set_xlabel(\"Epoch\")\n","    axs[1].legend(loc=\"upper right\")\n","    axs[1].set_title(\"Error eval\")\n","\n","    plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qW-Gxv-bnzDS"},"source":["def prepare_datasets(test_size, validation_size, X, y):\n","    #Loads data and splits it into train, validation and test sets.\n","\n","    # test_size = Value in [0, 1] indicating percentage of data set to allocate to test split\n","    # validation_size = Value in [0, 1] indicating percentage of train set to allocate to validation split\n","\n","    # X_train = Input training set\n","    # X_validation = Input validation set\n","    # X_test = Input test set\n","    # y_train = Target training set\n","    # y_validation = Target validation set\n","    # y_test = Target test set \n","\n","    # create train, validation and test split\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n","    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n","\n","    return X_train, X_validation, X_test, y_train, y_validation, y_test\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iq0ih3Yj74FG"},"source":["def build_RNN_model(input_shape):\n","    # Generates the RNN-LSTM model specific to this program (fixed number of layers)\n","    # input_shape = Shape of input set\n","\n","    # build network topology\n","    model = keras.Sequential()\n","\n","    # 2 LSTM layers\n","    model.add(keras.layers.LSTM(64, input_shape=input_shape, return_sequences=True))\n","    # The former RNN layer or layers should set return_sequences to True so that the following RNN layer or layers can have the full sequence as input.\n","    model.add(keras.layers.LSTM(64))\n","\n","    # dense layer\n","    model.add(keras.layers.Dense(64, activation='relu'))\n","    model.add(keras.layers.Dropout(0.3))\n","\n","    # output layer (10 different genres in the dataset)\n","    model.add(keras.layers.Dense(10, activation='softmax'))\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQRu3K8UCIDl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615203923615,"user_tz":-630,"elapsed":17774,"user":{"displayName":"martin gallo","photoUrl":"","userId":"09197733274002682158"}},"outputId":"93bafe7b-f589-4726-8576-6b86a78b3732"},"source":["if __name__ == \"__main__\":\n","\n","    # load data\n","    X, y = load_data(DATA_PATH)\n","\n","    print(X.shape)\n","    print()\n","    print(y.shape)\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["(9996, 130, 13)\n","\n","(9996,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cFxhYk4lmVVX"},"source":["# get train, validation, test splits\n","X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2, X, y) \n","    \n","#25% of data used for training, 20% for validation\n","\n","# create network\n","input_shape = (X_train.shape[1], X_train.shape[2]) # In this case, the input shape expects a 2-dimensional shape in the RNN\n","    \n","# First dimension: The dataset contains 130 samples which are audio signals over a certain time interval (30 secs)\n","# Second dimension: The actual coefficients that we extracted in previous processing [MFCCs (Mel Frequency Cepstral Coefficients)]\n","\n","model = build_RNN_model(input_shape)\n","\n","# compile model\n","optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n","model.compile(optimizer=optimiser,\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train model\n","history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30)"],"metadata":{"id":"kkPms8PpQRF3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot accuracy/error for training and validation\n","plot_history(history)\n","\n","# evaluate model on test set\n","test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n","print('\\nTest accuracy:', test_acc)"],"metadata":{"id":"DKRRGtYLQNYh"},"execution_count":null,"outputs":[]}]}