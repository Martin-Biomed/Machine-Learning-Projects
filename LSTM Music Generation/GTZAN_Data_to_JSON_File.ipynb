{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GTZAN_Data_to_JSON_File.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNQGN7ujN/azuQ8VRiLHds4"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"NbXgdNc7NUj_"},"source":["# This project is almost identical to the tutorial by Valerio Velardo: https://www.youtube.com/watch?v=szyGiObZymo\n","\n","# What this script does is it loads all the audio file in the GTZAN_Data.zip file and creates JSON files with all the saved MFCC matrices\n","\n","import json\n","import os\n","import math\n","import librosa"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S9-PZHw0OObg","executionInfo":{"status":"ok","timestamp":1615203358826,"user_tz":-630,"elapsed":19502,"user":{"displayName":"martin gallo","photoUrl":"","userId":"09197733274002682158"}},"outputId":"628576ca-e77a-49e5-fa02-57e8b208e7bf"},"source":["# I needed to connect my Google Drive because that was where my dataset was stored\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive') "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","source":["ORIGINAL_DATA_LOCATION = \"/content/gdrive/MyDrive/ML_Datasets/GTZAN_Data.zip\" #The original data was on my google drive, edit this to suit your needs\n","LOCAL_FILE_LOCATION = \"/content/GTZAN_Data.zip\" #This is where the data will be stored by default if using Google Colab"],"metadata":{"id":"9-Ti4OaSh7uz"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6vuOgIzWPESe","executionInfo":{"status":"ok","timestamp":1615203386490,"user_tz":-630,"elapsed":24721,"user":{"displayName":"martin gallo","photoUrl":"","userId":"09197733274002682158"}},"outputId":"c8cfb392-0df0-4c18-9ac9-4e9608505c11"},"source":["!cp -r {ORIGINAL_DATA_LOCATION} .\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["gdrive\tGTZAN_Data.zip\tsample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5rZ9dCXP4P-","executionInfo":{"status":"ok","timestamp":1615203417516,"user_tz":-630,"elapsed":843,"user":{"displayName":"martin gallo","photoUrl":"","userId":"09197733274002682158"}},"outputId":"ced3cb5e-b2aa-4fc3-ce92-5913ab1bb869"},"source":["!mkdir -p GTZAN_Data\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["gdrive\tGTZAN_Data  GTZAN_Data.zip  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Idmglq0bPrZU"},"source":["# We unzip all the audio files into the GTZAN_Data folder\n","\n","%cd GTZAN_Data\n","!unzip {LOCAL_FILE_LOCATION}\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mi4V0QCalBBZ"},"source":["# The file jazz.00054.wav was corrupted in the download for me\n","%cd genres_original/jazz/ \n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4uwO4c0an-mp"},"source":["# Because the data file was corrupted, I needed to remove it to allow the rest of the script to run (you may not have this problem)\n","!rm jazz.00054.wav\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJ-8n6MVljeS"},"source":["#Arbitrarily copied jazz.00019.wav as the new jazz.00054.wav (because the data file was corrupted, you may not need this step)\n","!cp jazz.00019.wav jazz.00054.wav\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"klvbPT7BNVb_"},"source":["DATASET_PATH = \"/content/GTZAN_Data/genres_original\" \n","JSON_PATH = \"/content/gdrive/MyDrive/ML_Datasets/data_10.json\" # You can edit this location to where you want to store the resulting JSON file\n","SAMPLE_RATE = 22050\n","TRACK_DURATION = 30 # measured in seconds\n","SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CsFfO2erNZtE"},"source":["def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n","  \n","    #Extracts MFCCs from music dataset and saves them into a json file along with genre labels.\n","        # dataset_path = Path to dataset\n","        # json_path = Path to json file used to save MFCCs\n","        # num_mfcc = Number of coefficients to extract\n","        # n_fft = Interval we consider to apply FFT (in terms of samples)\n","        # hop_length = Sliding window for FFT. Measured in # of samples\n","        # num_segments = Number of segments we want to divide sample tracks into\n","\n","    # dictionary to store mapping, labels, and MFCCs\n","    data = {\n","        \"mapping\": [],\n","        \"labels\": [],\n","        \"mfcc\": []\n","    }\n","\n","    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n","    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n","\n","    # loop through all genre sub-folder\n","    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n","\n","        # ensure we're processing a genre sub-folder level\n","        if dirpath is not dataset_path:\n","\n","            # save genre label (i.e., sub-folder name) in the mapping\n","            semantic_label = dirpath.split(\"/\")[-1]\n","            data[\"mapping\"].append(semantic_label)\n","            print(\"\\nProcessing: {}\".format(semantic_label))\n","\n","            # process all audio files in genre sub-dir\n","            for f in filenames:\n","\n","\t\t# load audio file\n","                file_path = os.path.join(dirpath, f)\n","                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n","\n","                # process all segments of audio file\n","                for d in range(num_segments):\n","\n","                    # calculate start and finish sample for current segment\n","                    start = samples_per_segment * d\n","                    finish = start + samples_per_segment\n","\n","                    # extract mfcc\n","                    mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n","                    mfcc = mfcc.T\n","\n","                    # store only mfcc feature with expected number of vectors\n","                    if len(mfcc) == num_mfcc_vectors_per_segment:\n","                        data[\"mfcc\"].append(mfcc.tolist())\n","                        data[\"labels\"].append(i-1)\n","                        print(\"{}, segment:{}\".format(file_path, d+1))\n","    \n","    # save MFCCs to json file\n","    with open(json_path, \"w\") as fp:\n","        json.dump(data, fp, indent=4)\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zfR5ND6GU6-5"},"source":["if __name__ == \"__main__\":\n","    save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)"],"execution_count":null,"outputs":[]}]}